{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add autoreload magic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "feature_view_name = 'ohlc_feature_view'\n",
    "feature_view_version = 10\n",
    "ohlc_window_sec = 60\n",
    "product_id = 'BTC/USD'\n",
    "last_n_days_to_fetch_from_store = 90\n",
    "last_n_days_to_test_model = 7\n",
    "discretization_thresholds = [-0.0001, 0.0001]\n",
    "prediction_window_sec = 60*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HOPSWORKS_API_KEY'] = '<PLACEHOLDER>'\n",
    "os.environ['HOPSWORKS_PROJECT_NAME'] = '<PLACEHOLDER>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/3285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-27 12:11:22.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mFetching OHLC data from the feature store\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.54s) \n"
     ]
    }
   ],
   "source": [
    "# Step 1    \n",
    "# Fetch the data from the feature store\n",
    "from tools.ohlc_data_reader import OhlcDataReader\n",
    "\n",
    "ohlc_data_reader = OhlcDataReader(\n",
    "    ohlc_window_sec=ohlc_window_sec,\n",
    "    feature_view_name=feature_view_name,\n",
    "    feature_view_version=feature_view_version,\n",
    ")\n",
    "\n",
    "logger.info('Fetching OHLC data from the feature store')\n",
    "\n",
    "ohlc_data = ohlc_data_reader.read_from_offline_store(\n",
    "    product_id=product_id,\n",
    "    last_n_days=last_n_days_to_fetch_from_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add a column to ohlc_data with a human-readable data, using\n",
    "# the ohlc_data['timestamp'] column in milliseconds\n",
    "ohlc_data['datetime'] = pd.to_datetime(ohlc_data['timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-27 12:11:31.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mSplitting the data into training and testing\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.training import split_train_test\n",
    "\n",
    "# Step 2\n",
    "# Split the data into training and testing using a cutoff date\n",
    "logger.info('Splitting the data into training and testing')\n",
    "ohlc_train, ohlc_test = split_train_test(\n",
    "    ohlc_data=ohlc_data,\n",
    "    last_n_days_to_test_model=last_n_days_to_test_model,\n",
    ")\n",
    "\n",
    "# print(ohlc_train.head())\n",
    "# print(ohlc_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-27 12:11:33.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mInterpolating missing candles for training data\u001b[0m\n",
      "\u001b[32m2024-06-27 12:11:33.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mInterpolating missing candles for testing data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.training import interpolate_missing_candles\n",
    "\n",
    "# Step 3\n",
    "# Preprocess the data for training and for testing\n",
    "# Interpolate missing candles\n",
    "logger.info('Interpolating missing candles for training data')\n",
    "ohlc_train = interpolate_missing_candles(ohlc_train, ohlc_window_sec)\n",
    "logger.info('Interpolating missing candles for testing data')\n",
    "ohlc_test = interpolate_missing_candles(ohlc_test, ohlc_window_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-27 12:11:34.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mCreating the target metric\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.training import create_target_metric\n",
    "\n",
    "# Step 4\n",
    "# Create the target metric as a new column in our dataframe for training and testing\n",
    "logger.info('Creating the target metric')\n",
    "ohlc_train = create_target_metric(\n",
    "    ohlc_train,\n",
    "    ohlc_window_sec,\n",
    "    discretization_thresholds,\n",
    "    prediction_window_sec,\n",
    ")\n",
    "ohlc_test = create_target_metric(\n",
    "    ohlc_test,\n",
    "    ohlc_window_sec,\n",
    "    discretization_thresholds,\n",
    "    prediction_window_sec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-27 12:11:35.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mDistribution of the target in the training data\u001b[0m\n",
      "\u001b[32m2024-06-27 12:11:35.202\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[34m\u001b[1mtarget\n",
      "2.0    49698\n",
      "0.0    47364\n",
      "1.0    21002\n",
      "Name: count, dtype: int64\u001b[0m\n",
      "\u001b[32m2024-06-27 12:11:35.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mDistribution of the target in the testing data\u001b[0m\n",
      "\u001b[32m2024-06-27 12:11:35.206\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1mtarget\n",
      "1.0    6973\n",
      "0.0    1561\n",
      "2.0    1541\n",
      "Name: count, dtype: int64\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Plot distribution of the target\n",
    "logger.info('Distribution of the target in the training data')\n",
    "logger.debug(ohlc_train['target'].value_counts())\n",
    "logger.info('Distribution of the target in the testing data')\n",
    "logger.debug(ohlc_test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training, let's split the features and the target\n",
    "X_train = ohlc_train.drop(columns=['target'])\n",
    "y_train = ohlc_train['target']\n",
    "X_test = ohlc_test.drop(columns=['target'])\n",
    "y_test = ohlc_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** TEST DATA ******\n",
      "Accuracy of the model on test data: 0.783424317617866\n",
      "Classification report of the model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.46      0.46      1561\n",
      "         1.0       0.93      0.93      0.93      6973\n",
      "         2.0       0.44      0.44      0.44      1541\n",
      "\n",
      "    accuracy                           0.78     10075\n",
      "   macro avg       0.61      0.61      0.61     10075\n",
      "weighted avg       0.78      0.78      0.78     10075\n",
      "\n",
      "****** TRAINING DATA ******\n",
      "Accuracy of the model: 0.4303174549396937\n",
      "Classification report of the model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.44      0.44     47364\n",
      "         1.0       0.33      0.33      0.33     21002\n",
      "         2.0       0.46      0.46      0.46     49698\n",
      "\n",
      "    accuracy                           0.43    118064\n",
      "   macro avg       0.41      0.41      0.41    118064\n",
      "weighted avg       0.43      0.43      0.43    118064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.baseline_model import BaselineModel\n",
    "\n",
    "# create model\n",
    "model = BaselineModel(\n",
    "    n_candles_into_future=prediction_window_sec // ohlc_window_sec,\n",
    "    discretization_thresholds=discretization_thresholds,\n",
    ")\n",
    "\n",
    "# generate predictions\n",
    "y_test_predictions = model.predict(X_test)\n",
    "\n",
    "# evalute our dummy model\n",
    "# Let's evaluate the model. It is a classifier with 3 classes\n",
    "\n",
    "print('****** TEST DATA ******')\n",
    "# Compute accuracy using scikit-learn\n",
    "accuracy = accuracy_score(y_test, y_test_predictions)\n",
    "print(f'Accuracy of the model on test data: {accuracy}')\n",
    "\n",
    "print(f'Classification report of the model:')\n",
    "print(classification_report(y_test, y_test_predictions))\n",
    "\n",
    "# generate predictions\n",
    "print('****** TRAINING DATA ******')\n",
    "y_train_predictions = model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_train_predictions)\n",
    "print(f'Accuracy of the model: {accuracy}')\n",
    "\n",
    "print(f'Classification report of the model:')\n",
    "print(classification_report(y_train, y_train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineering import add_features\n",
    "\n",
    "X_train = add_features(\n",
    "    X_train,\n",
    "    n_candles_into_future=prediction_window_sec // ohlc_window_sec,\n",
    "    discretization_thresholds=discretization_thresholds,\n",
    ")\n",
    "\n",
    "X_test = add_features(\n",
    "    X_test,\n",
    "    n_candles_into_future=prediction_window_sec // ohlc_window_sec,\n",
    "    discretization_thresholds=discretization_thresholds,\n",
    ")\n",
    "\n",
    "features_to_use = [\n",
    "    'rsi',\n",
    "    'momentum',\n",
    "    'std',\n",
    "    'last_observed_target',\n",
    "    'day_of_week',\n",
    "    'hour_of_day',\n",
    "    'minute_of_hour',\n",
    "]\n",
    "\n",
    "X_train_ = X_train[features_to_use]\n",
    "X_test_ = X_test[features_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a boosting tree algorithm -> XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** TEST DATA ******\n",
      "Accuracy on test data: 42.96%\n",
      "Classification report of the model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.45      0.38      1561\n",
      "         1.0       0.98      0.39      0.56      6973\n",
      "         2.0       0.18      0.59      0.27      1541\n",
      "\n",
      "    accuracy                           0.43     10075\n",
      "   macro avg       0.49      0.48      0.40     10075\n",
      "weighted avg       0.75      0.43      0.49     10075\n",
      "\n",
      "****** TRAINING DATA ******\n",
      "Accuracy: 60.85%\n",
      "Classification report of the model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.62      0.62     47364\n",
      "         1.0       0.68      0.35      0.46     21002\n",
      "         2.0       0.59      0.70      0.65     49698\n",
      "\n",
      "    accuracy                           0.61    118064\n",
      "   macro avg       0.63      0.56      0.57    118064\n",
      "weighted avg       0.62      0.61      0.60    118064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_, label=y_test)\n",
    "\n",
    "# Set parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Specify the objective for classification\n",
    "    'num_class': 3                 # Number of classes in the dataset,\n",
    "\n",
    "    # Add other parameters here\n",
    "    # These are things you can tune to optimize the model (aka hyperparameters)\n",
    "    # 'eta': 0.1,                    # Learning rate\n",
    "    # 'max_depth': 6,                # Maximum depth of a tree\n",
    "    # 'subsample': 0.8,              # Subsample ratio of the training instances\n",
    "    # 'colsample_bytree': 0.8,       # Subsample ratio of columns when constructing each tree\n",
    "    # 'gamma': 1,                    # Minimum loss reduction required to make a further partition\n",
    "    # 'alpha': 0,                    # L1 regularization term on weights\n",
    "    # 'lambda': 1,                   # L2 regularization term on weights\n",
    "    # 'scale_pos_weight': 1          # Balancing of positive and negative weights\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_predictions = model.predict(dtest)\n",
    "\n",
    "print('****** TEST DATA ******')\n",
    "# Calculate accuracy both on the training and test set\n",
    "accuracy = accuracy_score(y_test, y_test_predictions)\n",
    "print(f\"Accuracy on test data: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classifcation report\n",
    "print(f'Classification report of the model:')\n",
    "print(classification_report(y_test, y_test_predictions))\n",
    "\n",
    "print('****** TRAINING DATA ******')\n",
    "y_train_predictions = model.predict(dtrain)\n",
    "accuracy = accuracy_score(y_train, y_train_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "# Classifcation report\n",
    "print(f'Classification report of the model:')\n",
    "print(classification_report(y_train, y_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a simpler model, to make sure we are not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-27 13:15:30,682 WARNING: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "Accuracy on test data: 31.87%\n",
      "Accuracy on training data: 44.98%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "preds = model.predict(X_test_)\n",
    "\n",
    "# Calculate accuracy both on the training and test set\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(f'Accuracy on test data: {accuracy * 100:.2f}%')\n",
    "\n",
    "accuracy = accuracy_score(y_train, model.predict(X_train_))\n",
    "print(f'Accuracy on training data: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-QEbj44MR-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
